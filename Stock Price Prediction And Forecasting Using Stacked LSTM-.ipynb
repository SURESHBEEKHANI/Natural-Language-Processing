{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPFG8sc4571iC5pFA3/ipLZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SURESHBEEKHANI/Natural-Language-Processing/blob/main/Stock%20Price%20Prediction%20And%20Forecasting%20Using%20Stacked%20LSTM-.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stock-MArket-Forecasting /AAPL"
      ],
      "metadata": {
        "id": "QTgmFaXoStey"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XC3GdEeBC8hi"
      },
      "outputs": [],
      "source": [
        "# Import the pandas library which is used to read and manipulate data\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data from a CSV file into a pandas DataFrame\n",
        "data = pd.read_csv('/content/AAPL.csv')\n"
      ],
      "metadata": {
        "id": "BxJJnhDVDHvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the First few rows of the DataFrame 'data'\n",
        "data.head()"
      ],
      "metadata": {
        "id": "C5QnzyKoDRv6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the last few rows of the DataFrame 'data'\n",
        "data.tail()"
      ],
      "metadata": {
        "id": "5QWr06dsDrz0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check The Information  about all dataset\n",
        "data.info()"
      ],
      "metadata": {
        "id": "02E6zwcAGIbt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#5 Number summary of dataste\n",
        "data.describe()"
      ],
      "metadata": {
        "id": "GIDSeyLPIqvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1=data.reset_index()['close']"
      ],
      "metadata": {
        "id": "Aur2rvcwTp1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1"
      ],
      "metadata": {
        "id": "bwsIJ6lKT4VL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(df1)"
      ],
      "metadata": {
        "id": "jrke6MNXUJWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "scaler=MinMaxScaler(feature_range=(0,1))\n",
        "df1=scaler.fit_transform(np.array(df1).reshape(-1,1))"
      ],
      "metadata": {
        "id": "DY1Tt4-LQnBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1"
      ],
      "metadata": {
        "id": "9SMLVKQJdd2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##splitting dataset into train and test split\n",
        "#Traing data size is 65 % from all data\n",
        "training_size=int(len(df1)*0.65)\n",
        "#test data size is 35 % from all data\n",
        "test_size=len(df1)-training_size\n",
        "#\n",
        "train_data,test_data=df1[0:training_size,:],df1[training_size:len(df1),:1]"
      ],
      "metadata": {
        "id": "CuVuM94idtq9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.shape"
      ],
      "metadata": {
        "id": "pVIGVOMarx7k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train and test size of my data\n",
        "training_size,test_size"
      ],
      "metadata": {
        "id": "Fg4XvhUctizw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing"
      ],
      "metadata": {
        "id": "b79Sz5QI3GsK"
      }
    }
  ]
}