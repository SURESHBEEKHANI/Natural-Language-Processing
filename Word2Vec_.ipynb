{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPF//UxO+MXEtEjCWkbmKnH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SURESHBEEKHANI/Natural-Language-Processing/blob/main/Word2Vec_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gensim\n"
      ],
      "metadata": {
        "id": "Ja2hoJnk_449"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from gensim.models import Word2Vec  # Importing Word2Vec model from gensim library\n",
        "from nltk.tokenize import word_tokenize  # Importing word_tokenize function from NLTK library for tokenization\n",
        "import nltk  # Importing NLTK library for natural language processing tasks\n",
        "nltk.download('punkt')  # Downloading the 'punkt' tokenizer from NLTK (only need to do this once)\n",
        "import re  # Importing the 're' library for regular expressions"
      ],
      "metadata": {
        "id": "Ezib3l85BG1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "paragraph =\"\"\"\n",
        "Artificial Intelligence (AI) refers to the simulation of human intelligence in machines that are programmed to think and learn like humans. It encompasses a broad range of technologies and techniques, including machine learning, natural language processing, computer vision, robotics, and more. AI systems are designed to perform tasks that typically require human intelligence, such as recognizing patterns, making decisions, solving problems, understanding natural language, and even autonomously operating vehicles and robots.\n",
        "\n",
        "At its core, AI aims to replicate cognitive functions that humans associate with other human minds, such as learning, problem-solving, reasoning, perception, and language understanding. These capabilities enable AI systems to analyze large amounts of data, recognize patterns, and make predictions or decisions based on the data.\n",
        "\n",
        "AI has applications across various industries, from healthcare and finance to entertainment and transportation. It continues to evolve rapidly, driven by advances in computing power, data availability, and algorithms. The ethical implications and societal impacts of AI are also increasingly important considerations as its capabilities expand and its integration into everyday life grows deeper\"\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "SzXRndDkCuJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#preprocessing  text data\n",
        "text = re.sub(r'[^\\w\\s]', '', paragraph)  # Remove punctuation using regular expressions\n",
        "text= re.sub(r'\\d+', '', text)  # Remove digits using regular expressions\n",
        "text= re.sub(r'\\s+', ' ', text)  # Remove extra spaces\n",
        "text= re.sub(r'\\s+$', '', text)  # Remove trailing spaces\n",
        "text = text.lower()  # Convert text to lowercase"
      ],
      "metadata": {
        "id": "uXRNxGOZEGQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(text)"
      ],
      "metadata": {
        "id": "oOh9BXgsFO6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "nltk.download('stopwords') #Download nltk.download\n"
      ],
      "metadata": {
        "id": "PYlFGzNuIZjF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Use Tokenizing Technique  use for crops or pargrph convert into Sentences\n",
        "\n",
        "sentences=nltk.sent_tokenize(text)#Use sentence Tokenizing  Function convert Paragraph  into Token\n",
        "sentences=[nltk.word_tokenize(sentence) for sentence in sentences] #Use word Tokenizing Function Convert Sentance into words\n",
        "\n",
        "for i in range(len(sentences)):\n",
        "    sentences[i]=[word for word in sentences[i] if word.lower() not in nltk.corpus.stopwords.words('english')] #Remove Stopwords"
      ],
      "metadata": {
        "id": "oviZiHDVFtb3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cTuQSJxiIrzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply Word2Vec techniques\n",
        "model = Word2Vec(sentences, min_count=1)  # Create a Word2Vec model using the sentences\n",
        "\n",
        "# Get all words in the vocabulary\n",
        "words = model.wv.index_to_key  # Get a list of all words the model knows (vocabulary)\n",
        "print(\"Vocabulary:\", words)\n",
        "\n",
        "# Get the vector representation of the word 'artificial'\n",
        "print(\"Vector Representation :\", model.wv['learning'])\n",
        "\n",
        "# Find words that are most similar to 'learning'\n",
        "print(\"Most Similar Words :\", model.wv.most_similar('learning'))"
      ],
      "metadata": {
        "id": "O44NrzgrJjRb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}