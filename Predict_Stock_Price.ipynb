{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOjJ4PfBIbGTsLq8IieUdoP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SURESHBEEKHANI/Natural-Language-Processing/blob/main/Predict_Stock_Price.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "-40gKhgSik_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s6OWYgnSobyo"
      },
      "outputs": [],
      "source": [
        "data=pd.read_csv(\"/content/Data.csv\", encoding = \"ISO-8859-1\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "i2AY45HYj6xI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'Date' column is in datetime format or can be converted to it\n",
        "\n",
        "# Step 1: Filter rows for training data where Date is before '2015-01-01'\n",
        "train = data[data['Date'] < '2015-01-01']\n",
        "\n",
        "# Step 2: Filter rows for testing data where Date is after '2014-12-31'\n",
        "test = data[data['Date'] > '2014-12-31']\n",
        "\n",
        "# Explanation:\n",
        "# - 'train' DataFrame will contain all rows where Date is before January 1st, 2015.\n",
        "# - 'test' DataFrame will contain all rows where Date is after December 31st, 2014.\n",
        "#   (Note: This assumes '2014-12-31' is inclusive in 'test' as per the condition >, adjust as necessary)\n",
        "\n",
        "# Ensure the 'Date' column in your dataset is in datetime format or parsed as such for accurate filtering."
      ],
      "metadata": {
        "id": "q_VsPhHVkDip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecting columns 2 to 26 from the train DataFrame\n",
        "data = train.iloc[:, 2:27]\n",
        "\n",
        "# Removing all characters that are not letters (punctuations, numbers, etc.)\n",
        "data.replace(\"[^a-zA-Z]\", \" \", regex=True, inplace=True)\n",
        "\n",
        "# Creating a list of numbers from 0 to 24\n",
        "list1 = [i for i in range(25)]\n",
        "\n",
        "# Converting the list of numbers to strings\n",
        "new_Index = [str(i) for i in list1]\n",
        "\n",
        "# Renaming the columns of the data DataFrame\n",
        "data.columns = new_Index\n",
        "\n",
        "# Displaying the first 5 rows of the data DataFrame\n",
        "data.head(5)\n"
      ],
      "metadata": {
        "id": "lAt-sVXbmNY2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert all headlines in each column to lower case\n",
        "for index in new_Index:\n",
        "    data[index] = data[index].str.lower()\n",
        "\n",
        "# Display the first row of the modified data DataFrame\n",
        "data.head(1)\n"
      ],
      "metadata": {
        "id": "q2h5tRiFmpUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Join all values in the first row, from columns 0 to 24, into a single string\n",
        "joined_text = ' '.join(str(x) for x in data.iloc[1, 0:25])\n",
        "\n",
        "# Display the joined string\n",
        "print(joined_text)\n"
      ],
      "metadata": {
        "id": "yxTD4iWFnFr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize an empty list to store the combined text from each row\n",
        "headlines = []\n",
        "\n",
        "# Loop over each row in the data DataFrame\n",
        "for row in range(0, len(data.index)):\n",
        "    # Combine text from columns 0 to 24 into a single string for the current row\n",
        "    combined_text = ' '.join(str(x) for x in data.iloc[row, 0:25])\n",
        "\n",
        "    # Add the combined text to the headlines list\n",
        "    headlines.append(combined_text)\n",
        "\n",
        "# Display the first few combined headlines (optional)\n",
        "print(headlines[:5])\n"
      ],
      "metadata": {
        "id": "esLCI4PQnVMR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "headlines[0]"
      ],
      "metadata": {
        "id": "SfTtY6tjn4Yt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "# CountVectorizer: Helps in converting text data into a matrix of token counts (Bag of Words)\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "# RandomForestClassifier: A machine learning algorithm used for classification tasks\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Implementing Bag of Words model\n",
        "# CountVectorizer converts text data into a matrix of word counts, here we use pairs of words (bigrams)\n",
        "countvector = CountVectorizer(ngram_range=(2, 2))\n",
        "\n",
        "# Transform the headlines into a matrix of word counts\n",
        "# This converts the list of headlines into numerical data that can be used by the machine learning algorithm\n",
        "traindataset = countvector.fit_transform(headlines)\n",
        "\n",
        "# Implementing Random Forest Classifier\n",
        "# RandomForestClassifier is a machine learning algorithm used to classify data into categories\n",
        "# n_estimators=200: The number of trees in the forest\n",
        "# criterion='entropy': The function to measure the quality of a split\n",
        "randomclassifier = RandomForestClassifier(n_estimators=200, criterion='entropy')\n",
        "\n",
        "# Fit the RandomForest model with the training data\n",
        "# randomclassifier.fit: Trains the Random Forest model using the transformed headlines (traindataset) and the labels from the training data\n",
        "randomclassifier.fit(traindataset, train['Label'])\n",
        "\n",
        "# After running this code, the Random Forest model will be trained and ready to make predictions\n"
      ],
      "metadata": {
        "id": "fT_9YtU9n9-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting for the Test Dataset\n",
        "\n",
        "# Initialize an empty list to store the transformed test headlines\n",
        "test_transform = []\n",
        "\n",
        "# Loop over each row in the test DataFrame\n",
        "for row in range(0, len(test.index)):\n",
        "    # Combine text from columns 2 to 26 into a single string for the current row\n",
        "    combined_text = ' '.join(str(x) for x in test.iloc[row, 2:27])\n",
        "\n",
        "    # Add the combined text to the test_transform list\n",
        "    test_transform.append(combined_text)\n",
        "\n",
        "# Transform the test headlines into a matrix of word counts\n",
        "# This converts the list of test headlines into numerical data that can be used by the machine learning algorithm\n",
        "test_dataset = countvector.transform(test_transform)\n",
        "\n",
        "# Use the trained Random Forest model to make predictions on the test data\n",
        "# The model will predict the category (label) for each headline in the test data\n",
        "predictions = randomclassifier.predict(test_dataset)\n",
        "\n",
        "# After running this code, the 'predictions' will contain the predicted labels for the test headlines\n"
      ],
      "metadata": {
        "id": "OCtBnvj5o5Ho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import library to check accuracy\n",
        "# These tools help us evaluate how well our model is performing\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "# This matrix shows the number of correct and incorrect predictions made by the model\n",
        "# Rows represent actual categories, and columns represent predicted categories\n",
        "matrix = confusion_matrix(test['Label'], predictions)\n",
        "print(matrix)\n",
        "\n",
        "# Calculate the accuracy score\n",
        "# This score tells us the percentage of correct predictions made by the model\n",
        "score = accuracy_score(test['Label'], predictions)\n",
        "print(score)\n",
        "\n",
        "# Generate a detailed classification report\n",
        "# This report provides precision, recall, and F1 score for each category\n",
        "report = classification_report(test['Label'], predictions)\n",
        "print(report)\n"
      ],
      "metadata": {
        "id": "W4f9JD5lpcdx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}