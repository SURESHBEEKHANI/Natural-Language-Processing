{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNQAJxRRUJ56nRCFNTs/EMJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SURESHBEEKHANI/Natural-language-processing-/blob/main/Stemming_And_Lemmatization_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **Stemming and lemmatization**\n",
        "\n",
        "Stemming and lemmatization are two common techniques used in natural language processing (NLP) and text mining to preprocess text data. Their primary goal is to reduce words to their base or root form, which helps in standardizing vocabulary and improving the efficiency of text-based operations like indexing, searching, and analysis.\n",
        "\n",
        "Stemming:\n",
        "Definition: Stemming is the process of reducing words to their word stem or root form. It involves chopping off the ends of words to remove affixes such as prefixes and suffixes. The resulting stem may not be a valid word in the language.\n",
        "\n",
        "Purpose: Stemming is typically used to normalize words for the purpose of indexing and retrieval. It aims to reduce variants of words to a common base form, even if the stem itself is not semantically correct.\n",
        "\n",
        "Example:\n",
        "\n",
        "Original: walking, walked, walks\n",
        "Stem: walk\n",
        "Lemmatization:\n",
        "Definition: Lemmatization, on the other hand, also reduces words to their base or root form, but it ensures that the root belongs to the language. It uses vocabulary and morphological analysis of words to accurately derive the lemma, which is the canonical form of a set of words.\n",
        "\n",
        "Purpose: Lemmatization is more sophisticated than stemming as it takes into account the context and meaning of words. It aims to transform words to their dictionary form, which is linguistically correct and meaningful.\n",
        "\n",
        "Example:\n",
        "\n",
        "Original: went, going, gone\n",
        "Lemma: go\n",
        "Key Differences:\n",
        "Output: Stemming may produce words that are not actual words, whereas lemmatization always results in actual words.\n",
        "Accuracy: Lemmatization is more accurate but computationally expensive compared to stemming.\n",
        "Use Cases: Stemming is often used in information retrieval systems and search engines where speed is crucial, while lemmatization is preferred in applications requiring precision and understanding of the text's context.\n",
        "In practice, the choice between stemming and lemmatization depends on the specific requirements of the NLP task and the trade-off between speed and accura"
      ],
      "metadata": {
        "id": "K0qC8F0KHEGO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WjOI8jmEGNhV"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')  # This downloads the necessary resources for tokenization\n",
        "nltk.download('averaged_perceptron_tagger')  # For part-of-speech tagging\n",
        "nltk.download('wordnet')  # For lemmatization\n",
        "nltk.download('stopwords')  # For stopwords\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Initialize the Porter Stemmer\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "# Example words to stem\n",
        "words = [\"walking\", \"walked\", \"walks\"]\n",
        "\n",
        "# Stem each word and print the results\n",
        "for word in words:\n",
        "    stemmed_word = stemmer.stem(word)\n",
        "    print(f\"Original: {word}, Stemmed: {stemmed_word}\")\n"
      ],
      "metadata": {
        "id": "7Q06aJzWI1nn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import LancasterStemmer\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Initialize the Lancaster Stemmer\n",
        "stemmer = LancasterStemmer()\n",
        "\n",
        "# Example words to stem\n",
        "words = [\"walking\", \"walked\", \"walks\"]\n",
        "\n",
        "# Stem each word and print the results\n",
        "for word in words:\n",
        "    stemmed_word = stemmer.stem(word)\n",
        "    print(f\"Original: {word}, Stemmed: {stemmed_word}\")\n"
      ],
      "metadata": {
        "id": "XwNvDH8jJdSk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import StemmerI\n",
        "import re\n",
        "\n",
        "# Example usage\n",
        "stemmer = RegexpStemmer(r'ing$|ed$|es$|s$', min_length=2)\n",
        "\n",
        "words = [\"running\", \"played\", \"walks\"]\n",
        "\n",
        "for word in words:\n",
        "    stemmed_word = stemmer.stem(word)\n",
        "    print(f\"Original: {word}, Stemmed: {stemmed_word}\")\n"
      ],
      "metadata": {
        "id": "tcnFg3LDKKOA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import SnowballStemmer\n",
        "\n",
        "# Initialize the Snowball Stemmer for English\n",
        "stemmer = SnowballStemmer(\"english\")\n",
        "\n",
        "# Example words to stem\n",
        "words = [\"running\", \"jumps\", \"easily\", \"fairly\"]\n",
        "\n",
        "# Stem each word and print the results\n",
        "for word in words:\n",
        "    stemmed_word = stemmer.stem(word)\n",
        "    print(f\"Original: {word}, Stemmed: {stemmed_word}\")\n"
      ],
      "metadata": {
        "id": "mlXzGFaOKI76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lemmatization"
      ],
      "metadata": {
        "id": "e1pIzKN9PmW6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('punkt')  # Optional: for tokenizing sentences\n"
      ],
      "metadata": {
        "id": "WVNj4a-zPkJC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Initialize the WordNet Lemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n"
      ],
      "metadata": {
        "id": "uLMBJuqzQOci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = [\"running\", \"jumps\", \"easily\", \"fairly\", \"better\"]\n",
        "\n",
        "for word in words:\n",
        "    lemma = lemmatizer.lemmatize(word ,pos=\"v\")\n",
        "    print(f\"Original: {word}, Lemma: {lemma}\")\n"
      ],
      "metadata": {
        "id": "cwrjGTM_QbUJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}